{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "d7yZRhX2wiR3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: transformers in c:\\programdata\\anaconda3\\lib\\site-packages (4.24.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.11.4)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (22.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (0.10.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (4.64.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (1.23.5)\n",
      "Requirement already satisfied: filelock in c:\\programdata\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\pradeep verma\\appdata\\roaming\\python\\python310\\site-packages (from huggingface-hub<1.0,>=0.10.0->transformers) (4.5.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (2022.12.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zR1dyQeqaPYk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for the presence of GPU and print its name\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "MqmgUY0aaZAo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 18067674140529599922\n",
       " xla_global_id: -1]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List all local devices\n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "6-RKGi0zsaFY"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Check if CUDA (GPU) is available\n",
    "if torch.cuda.is_available():\n",
    "    # Set the device to CUDA\n",
    "    device = torch.device(\"cuda\")\n",
    "    # Print the number of available CUDA devices\n",
    "    print(torch.cuda.device_count())\n",
    "    \n",
    "    # Print the name of the first CUDA device\n",
    "    print(torch.cuda.get_device_name(0))\n",
    "\n",
    "else:\n",
    "    # Set the device to CPU\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QcA6rcFuxBWZ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "187nr9hFVai1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(37500, 7)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "txt_path = 'AnonymizedClinicalAbbreviationsAndAcronymsDataSet.txt'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "data_pd = pd.read_csv(txt_path, sep=\"|\", header=None, encoding='cp1252')\n",
    "\n",
    "# Rename the columns\n",
    "data_pd = data_pd.rename(columns={0: 'Abbreviation', 1: 'Expansion', 2: 'ABB_frm', 3: \"start_pos\", 4: \"end_pos\", 5: \"info\", 6: \"context\"}, inplace=False)\n",
    "\n",
    "# Print the shape of the DataFrame\n",
    "print(data_pd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Abbreviation</th>\n",
       "      <th>Expansion</th>\n",
       "      <th>ABB_frm</th>\n",
       "      <th>start_pos</th>\n",
       "      <th>end_pos</th>\n",
       "      <th>info</th>\n",
       "      <th>context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB.</td>\n",
       "      <td>231.0</td>\n",
       "      <td>233.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_%#NAME#%_ _%#NAME#%_ is a 29-year-old gravida...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB.</td>\n",
       "      <td>249.0</td>\n",
       "      <td>251.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>She is now bleeding quite heavily. Ultrasound ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>223.0</td>\n",
       "      <td>224.0</td>\n",
       "      <td>PAST OB HISTORY</td>\n",
       "      <td>ALLERGIES: Heparin and Imitrex. PAST OB HISTOR...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB.</td>\n",
       "      <td>194.0</td>\n",
       "      <td>196.0</td>\n",
       "      <td>HISTORY OF THE PRESENT ILLNESS</td>\n",
       "      <td>She had a pelvic ultrasound at Park Nicollet o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AB</td>\n",
       "      <td>abortion</td>\n",
       "      <td>AB</td>\n",
       "      <td>114.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>PAST OB-GYN HISTORY</td>\n",
       "      <td>On _%#MMDD2007#%_, normal anatomy with anterio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Abbreviation Expansion ABB_frm  start_pos  end_pos  \\\n",
       "0           AB  abortion     AB.      231.0    233.0   \n",
       "1           AB  abortion     AB.      249.0    251.0   \n",
       "2           AB  abortion      AB      223.0    224.0   \n",
       "3           AB  abortion     AB.      194.0    196.0   \n",
       "4           AB  abortion      AB      114.0    115.0   \n",
       "\n",
       "                             info  \\\n",
       "0                             NaN   \n",
       "1                             NaN   \n",
       "2                 PAST OB HISTORY   \n",
       "3  HISTORY OF THE PRESENT ILLNESS   \n",
       "4             PAST OB-GYN HISTORY   \n",
       "\n",
       "                                             context  \n",
       "0  _%#NAME#%_ _%#NAME#%_ is a 29-year-old gravida...  \n",
       "1  She is now bleeding quite heavily. Ultrasound ...  \n",
       "2  ALLERGIES: Heparin and Imitrex. PAST OB HISTOR...  \n",
       "3  She had a pelvic ultrasound at Park Nicollet o...  \n",
       "4  On _%#MMDD2007#%_, normal anatomy with anterio...  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kO_uIQaKQRza"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 7)\n"
     ]
    }
   ],
   "source": [
    "data_pd=data_pd[data_pd['Abbreviation'] == 'AB']\n",
    "print(data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "WdEq_v8bu3sH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n",
      "(498, 7)\n"
     ]
    }
   ],
   "source": [
    "#check number of expansion in the dataset before filtering\n",
    "print(len(data_pd[\"Expansion\"].unique()))\n",
    "\n",
    "#filtering dataset \n",
    "data_pd.drop(data_pd[data_pd['Expansion'] == \"UNSURED SENSE\"].index, inplace = True)\n",
    "data_pd.drop(data_pd[data_pd['Expansion'] == \"GENERAL ENGLISH\"].index, inplace = True)\n",
    "data_pd.drop(data_pd[data_pd['Expansion'] == \"NAME\"].index, inplace = True)\n",
    "\n",
    "# check dataset size after filtering\n",
    "print(data_pd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "ZkgY1gH7m1HL"
   },
   "outputs": [],
   "source": [
    "# fuction to assign numerical value to the expansion\n",
    "def func(unique_expansion, ex):\n",
    "  ex= str(ex)\n",
    "  for i in unique_expansion.items():\n",
    "    if i[0] == ex:\n",
    "      return i[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "i4zpSvj5kTWi"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Get unique values of Expansion column\n",
    "Expansion_unique = data_pd[\"Expansion\"].unique()\n",
    "\n",
    "# Get context column values\n",
    "context = data_pd[\"context\"].values\n",
    "\n",
    "# Create numerical labels for unique expansions\n",
    "num = np.arange(0, 348, 1).tolist()\n",
    "unique_expansion = dict(zip(Expansion_unique, num))\n",
    "\n",
    "# Initialize a list to store all labels\n",
    "all_label = []\n",
    "\n",
    "# Iterate through each row of the DataFrame\n",
    "for index, row in data_pd.iterrows():\n",
    "    # Iterate through unique_expansion dictionary items\n",
    "    for i in unique_expansion.items():\n",
    "        # Check if the expansion in the row matches with any unique expansion\n",
    "        if i[0] == row[1]:\n",
    "            # Append the corresponding numerical label to all_label list\n",
    "            all_label.append(i[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "3_UQ9okqd1Zq"
   },
   "outputs": [],
   "source": [
    "# Create a dictionary mapping each word in Expansion_unique to its index\n",
    "word2index_dict = {word: i for (i, word) in enumerate(Expansion_unique)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "1DpDwPzR6S8q"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a DataFrame from word2index_dict\n",
    "label_df = pd.DataFrame(list(word2index_dict.items()), columns=['expansion', 'label'])\n",
    "\n",
    "# Save the DataFrame to a TSV file\n",
    "label_df.to_csv('label_expansion.tsv', sep='|', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "sSif6ujY2g7d"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def cleaning(context_):\n",
    "    # Remove patterns like \"_%#\\S+\"\n",
    "    x = re.sub(\"_%#\\S+\", \"\", context_)\n",
    "    # Remove punctuation marks\n",
    "    x = re.sub('[%s]' % re.escape(string.punctuation), ' ', x)\n",
    "    # Remove alphanumeric characters\n",
    "    x = re.sub(r'\\w*\\d+\\w*', '', x)\n",
    "    # Replace multiple spaces with a single space\n",
    "    x = re.sub('\\s{2,}', \" \", x)\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "x9oRiBmj1A3I"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a new DataFrame for filtered data\n",
    "filtered_data = pd.DataFrame()\n",
    "\n",
    "# Assign cleaned text data to 'content' column\n",
    "filtered_data['content'] = data_pd['context'].apply(cleaning)\n",
    "\n",
    "# Assign Expansion column to 'expansion' column\n",
    "filtered_data['expansion'] = data_pd['Expansion']\n",
    "\n",
    "# Assign labels to 'label' column\n",
    "filtered_data['label'] = all_label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "QLwRzNLQkV2N"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data['label'][498]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "fhy95DydAGgv"
   },
   "outputs": [],
   "source": [
    "#override dataset\n",
    "class DisambiguateDataset(Dataset):\n",
    "\n",
    "  def __init__(self, data: pd.DataFrame, tokenizer, max_token_len ):\n",
    "    # Initialize the dataset with the provided DataFrame, tokenizer, and maximum token length\n",
    "    self.data = data\n",
    "    self.tokenizer = tokenizer\n",
    "    self.max_token_len = max_token_len\n",
    "\n",
    "  def __len__(self):\n",
    "    # Return the number of samples in the dataset (number of rows in the DataFrame)\n",
    "    return self.data.shape[0]\n",
    "\n",
    "  def __getitem__(self, index: int):\n",
    "    # Retrieve a single sample from the dataset at the given index\n",
    "    data_row = self.data.iloc[index]\n",
    "    context =data_row['content']\n",
    "    expansion = data_row['expansion']\n",
    "    label_ = data_row['label']\n",
    "      \n",
    "    # Encode the expansion and context using the provided tokenize\n",
    "    encoding = self.tokenizer.encode_plus(\n",
    "        expansion, context, \n",
    "        add_special_tokens = True,\n",
    "        max_length = 128,\n",
    "        return_token_type_ids = True,\n",
    "        padding = \"max_length\",\n",
    "        truncation =True,\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = \"pt\"\n",
    "     \n",
    "    )\n",
    "    # Return a dictionary containing the encoded input IDs, attention mask, token type IDs, and the label converted to a PyTorch tensor\n",
    "    return dict(\n",
    "      input_ids = encoding[\"input_ids\"].flatten(),\n",
    "      attention_mask = encoding[\"attention_mask\"].flatten(),\n",
    "      token_type_ids = encoding[\"token_type_ids\"].flatten(),\n",
    "      label_ = torch.tensor(label_,dtype = torch.long)\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5TctrJoJPlOm",
    "outputId": "0dedc7d6-e543-4c6e-b864-99bce94d4216"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((398, 3), (50, 3), (50, 3))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RANDOM_SEED = 42\n",
    "MAX_LEN = 128\n",
    "BATCH_SIZE = 8\n",
    "EPOCHS = 2\n",
    "\n",
    "# divide the data set to training and validation dataset and check the new size for both\n",
    "train_df, test_df = train_test_split(filtered_data,test_size=0.2, random_state = RANDOM_SEED)\n",
    "val_df, test_df = train_test_split(test_df,test_size=0.5, random_state = RANDOM_SEED)\n",
    "train_df.shape, val_df.shape, test_df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HWvkbjiIR4ct",
    "outputId": "b6d0f1ea-99ce-4c88-dd97-9f8ced850198"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['content', 'expansion', 'label'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 32
    },
    "id": "Vd2KPmDWMpGW",
    "outputId": "665d834a-9ea6-4b63-da0c-4ccbf5b8ddc7"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>expansion</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>At the time of admission, her cervix was noted...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>450</th>\n",
       "      <td>2. Spinal meningitis as a child. PAST SURGICAL...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>This pregnancy complicated by AMA, previous hi...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>The uterus itself is small, anterior and mobil...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>PAST OBSTETRICAL HISTORY: 1. _%#MM#%_ 2001, ce...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>Cervix is closed. Uterus is anteverted, 6 week...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>PAST MEDICAL HISTORY: Inappropriate sinus tach...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>456</th>\n",
       "      <td>Good fetal movement. Prenatal care started at ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>457</th>\n",
       "      <td>Urine culture within normal limits. Hemoglobin...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>DOB: PREOP HISTORY AND PHYSICAL AND EMERGENCY ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>LUNGS: Clear. ABDOMEN: Soft. PELVIC: External ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>460</th>\n",
       "      <td>PRENATAL CARE: She received at the Native Amer...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>461</th>\n",
       "      <td>3. Rubella immune. 4. Hepatitis B, HIV and RPR...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>462</th>\n",
       "      <td>ADMISSION DIAGNOSIS: Ectopic pregnancy versus ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>463</th>\n",
       "      <td>LABORATORY DATA: Blood type A positive, antibo...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>The fetus, however, showed no cardiac activity...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>Again, the ultrasound results from today was d...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>CHIEF COMPLAINT: Missed AB. HISTORY OF PRESENT...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>PAST SURGICAL HISTORY: 1. Cholecystectomy. 2. ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Given the history of classical C-section by he...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>3. GBS negative on _%#MM#%_ _%#DD#%_, 2006. 4....</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>470</th>\n",
       "      <td>PAST SURGICAL HISTORY: 1. Status post ovarian ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: Missed AB at 8-plus we...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>Urine culture 10-50,000 Staph. Hepatitis B sur...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>1. A1 gestational diabetes. 2. Polycystic ovar...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>She is having contractions every 6 minutes tha...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>She was admitted on _%#MMDD2003#%_ for spontan...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>No hepatosplenomegaly. PELVIC: Deferred to sur...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>3. Low-lying placenta and third-trimester blee...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>1. Psychiatric illness (as above). Details per...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>1. This is a 26-year-old G3, P0-0-2-0, at 6 we...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>2. History of iron deficiency anemia during he...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>Raised the question regarding possible seizure...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>482</th>\n",
       "      <td>CHIEF COMPLAINT: Vaginal bleeding, probable sp...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>PAST MEDICAL HISTORY: 1. Psychiatric illness: ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>6. Topamax 100 mg at h.s. ALLERGIES: Vistaril ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>5. Remote history of pneumonia and pleurisy. 6...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>1. Anxiety disorder (details per Psychiatry). ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>She has a partner in her room with her at all ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>She says that the second day of her period is ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>PREOPERATIVE DIAGNOSIS: Missed AB. POSTOPERATI...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>Hemoglobin 11.8 to 12.6, platelets of 239, 000...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>PRENATAL CARE: Prenatal care was initiated at ...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>She is not allergic to any medications. The pa...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>She had a total weight gain of 31 pounds. PREN...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>SURGICAL: 1) Knee surgery x 3. 2) Cesarean sec...</td>\n",
       "      <td>blood group in ABO system</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>She is scheduled for vacuum curettage at Fairv...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>Pacemaker was considered, but it was elected t...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>It was slightly more irregular, and because of...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>SUMMARY OF HOSPITAL COURSE: _%#NAME#%_ _%#NAME...</td>\n",
       "      <td>abortion</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               content  \\\n",
       "449  At the time of admission, her cervix was noted...   \n",
       "450  2. Spinal meningitis as a child. PAST SURGICAL...   \n",
       "451  This pregnancy complicated by AMA, previous hi...   \n",
       "452  The uterus itself is small, anterior and mobil...   \n",
       "453  PAST OBSTETRICAL HISTORY: 1. _%#MM#%_ 2001, ce...   \n",
       "454  Cervix is closed. Uterus is anteverted, 6 week...   \n",
       "455  PAST MEDICAL HISTORY: Inappropriate sinus tach...   \n",
       "456  Good fetal movement. Prenatal care started at ...   \n",
       "457  Urine culture within normal limits. Hemoglobin...   \n",
       "458  DOB: PREOP HISTORY AND PHYSICAL AND EMERGENCY ...   \n",
       "459  LUNGS: Clear. ABDOMEN: Soft. PELVIC: External ...   \n",
       "460  PRENATAL CARE: She received at the Native Amer...   \n",
       "461  3. Rubella immune. 4. Hepatitis B, HIV and RPR...   \n",
       "462  ADMISSION DIAGNOSIS: Ectopic pregnancy versus ...   \n",
       "463  LABORATORY DATA: Blood type A positive, antibo...   \n",
       "464  The fetus, however, showed no cardiac activity...   \n",
       "465  Again, the ultrasound results from today was d...   \n",
       "466  CHIEF COMPLAINT: Missed AB. HISTORY OF PRESENT...   \n",
       "467  PAST SURGICAL HISTORY: 1. Cholecystectomy. 2. ...   \n",
       "468  Given the history of classical C-section by he...   \n",
       "469  3. GBS negative on _%#MM#%_ _%#DD#%_, 2006. 4....   \n",
       "470  PAST SURGICAL HISTORY: 1. Status post ovarian ...   \n",
       "471  PREOPERATIVE DIAGNOSIS: Missed AB at 8-plus we...   \n",
       "472  Urine culture 10-50,000 Staph. Hepatitis B sur...   \n",
       "473  1. A1 gestational diabetes. 2. Polycystic ovar...   \n",
       "474  She is having contractions every 6 minutes tha...   \n",
       "475  She was admitted on _%#MMDD2003#%_ for spontan...   \n",
       "476  No hepatosplenomegaly. PELVIC: Deferred to sur...   \n",
       "477  3. Low-lying placenta and third-trimester blee...   \n",
       "478  1. Psychiatric illness (as above). Details per...   \n",
       "479  1. This is a 26-year-old G3, P0-0-2-0, at 6 we...   \n",
       "480  2. History of iron deficiency anemia during he...   \n",
       "481  Raised the question regarding possible seizure...   \n",
       "482  CHIEF COMPLAINT: Vaginal bleeding, probable sp...   \n",
       "484  PAST MEDICAL HISTORY: 1. Psychiatric illness: ...   \n",
       "485  6. Topamax 100 mg at h.s. ALLERGIES: Vistaril ...   \n",
       "486  5. Remote history of pneumonia and pleurisy. 6...   \n",
       "487  1. Anxiety disorder (details per Psychiatry). ...   \n",
       "488  She has a partner in her room with her at all ...   \n",
       "489  She says that the second day of her period is ...   \n",
       "490  PREOPERATIVE DIAGNOSIS: Missed AB. POSTOPERATI...   \n",
       "491  Hemoglobin 11.8 to 12.6, platelets of 239, 000...   \n",
       "492  PRENATAL CARE: Prenatal care was initiated at ...   \n",
       "493  She is not allergic to any medications. The pa...   \n",
       "494  She had a total weight gain of 31 pounds. PREN...   \n",
       "495  SURGICAL: 1) Knee surgery x 3. 2) Cesarean sec...   \n",
       "496  She is scheduled for vacuum curettage at Fairv...   \n",
       "497  Pacemaker was considered, but it was elected t...   \n",
       "498  It was slightly more irregular, and because of...   \n",
       "499  SUMMARY OF HOSPITAL COURSE: _%#NAME#%_ _%#NAME...   \n",
       "\n",
       "                     expansion  label  \n",
       "449                   abortion      0  \n",
       "450                   abortion      0  \n",
       "451                   abortion      0  \n",
       "452                   abortion      0  \n",
       "453                   abortion      0  \n",
       "454                   abortion      0  \n",
       "455                   abortion      0  \n",
       "456                   abortion      0  \n",
       "457                   abortion      0  \n",
       "458                   abortion      0  \n",
       "459                   abortion      0  \n",
       "460                   abortion      0  \n",
       "461                   abortion      0  \n",
       "462                   abortion      0  \n",
       "463                   abortion      0  \n",
       "464                   abortion      0  \n",
       "465                   abortion      0  \n",
       "466                   abortion      0  \n",
       "467                   abortion      0  \n",
       "468                   abortion      0  \n",
       "469                   abortion      0  \n",
       "470                   abortion      0  \n",
       "471                   abortion      0  \n",
       "472                   abortion      0  \n",
       "473                   abortion      0  \n",
       "474                   abortion      0  \n",
       "475                   abortion      0  \n",
       "476                   abortion      0  \n",
       "477                   abortion      0  \n",
       "478                   abortion      0  \n",
       "479                   abortion      0  \n",
       "480                   abortion      0  \n",
       "481                   abortion      0  \n",
       "482                   abortion      0  \n",
       "484                   abortion      0  \n",
       "485                   abortion      0  \n",
       "486                   abortion      0  \n",
       "487                   abortion      0  \n",
       "488                   abortion      0  \n",
       "489                   abortion      0  \n",
       "490                   abortion      0  \n",
       "491                   abortion      0  \n",
       "492                   abortion      0  \n",
       "493                   abortion      0  \n",
       "494                   abortion      0  \n",
       "495  blood group in ABO system      2  \n",
       "496                   abortion      0  \n",
       "497                   abortion      0  \n",
       "498                   abortion      0  \n",
       "499                   abortion      0  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_data.tail(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "XBJpabNcmEBL"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at emilyalsentzer/Bio_ClinicalBERT were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Download Bio_clinicalBERT \n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel, BertForNextSentencePrediction, BertTokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "FFHS9KiIrGzC"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at NLP4H/ms_bert were not used when initializing BertModel: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "#Download ms_bert\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "model_name = \"NLP4H/ms_bert\"\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "IvBJ74U1gyzf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 199 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "embeddings.word_embeddings.weight                       (30522, 768)\n",
      "embeddings.position_embeddings.weight                     (512, 768)\n",
      "embeddings.token_type_embeddings.weight                     (2, 768)\n",
      "embeddings.LayerNorm.weight                                   (768,)\n",
      "embeddings.LayerNorm.bias                                     (768,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "encoder.layer.0.attention.self.query.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.query.bias                     (768,)\n",
      "encoder.layer.0.attention.self.key.weight                 (768, 768)\n",
      "encoder.layer.0.attention.self.key.bias                       (768,)\n",
      "encoder.layer.0.attention.self.value.weight               (768, 768)\n",
      "encoder.layer.0.attention.self.value.bias                     (768,)\n",
      "encoder.layer.0.attention.output.dense.weight             (768, 768)\n",
      "encoder.layer.0.attention.output.dense.bias                   (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.weight             (768,)\n",
      "encoder.layer.0.attention.output.LayerNorm.bias               (768,)\n",
      "encoder.layer.0.intermediate.dense.weight                (3072, 768)\n",
      "encoder.layer.0.intermediate.dense.bias                      (3072,)\n",
      "encoder.layer.0.output.dense.weight                      (768, 3072)\n",
      "encoder.layer.0.output.dense.bias                             (768,)\n",
      "encoder.layer.0.output.LayerNorm.weight                       (768,)\n",
      "encoder.layer.0.output.LayerNorm.bias                         (768,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "encoder.layer.11.output.LayerNorm.weight                      (768,)\n",
      "encoder.layer.11.output.LayerNorm.bias                        (768,)\n",
      "pooler.dense.weight                                       (768, 768)\n",
      "pooler.dense.bias                                             (768,)\n"
     ]
    }
   ],
   "source": [
    "# Get the list of named parameters from the model\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "# Print the total number of different named parameters in the model\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "# Print information about the embedding layer\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "# Print the names and sizes of the parameters in the embedding layer\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "# Print information about the first transformer layer\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "# Print the names and sizes of the parameters in the first transformer layer\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "# Print information about the output layer\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "# Print the names and sizes of the parameters in the output layer\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "2ZrSM_LtTDpz"
   },
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "  ds = DisambiguateDataset(df, tokenizer, max_len)\n",
    "\n",
    "  return torch.utils.data.DataLoader(ds, batch_size = batch_size, shuffle = True )  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "rwNKKzq1T-zI"
   },
   "outputs": [],
   "source": [
    "train_data_loader = create_data_loader(train_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(val_df, tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(test_df, tokenizer, MAX_LEN, BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "QNZLYjr4bWuP"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'attention_mask', 'token_type_ids', 'label_'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = next(iter(val_data_loader))\n",
    "data.keys()\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "70FgbcJqhQJ3"
   },
   "outputs": [],
   "source": [
    "class DisambiguateClassifier(nn.Module):\n",
    "\n",
    "  def __init__(self, n_classes):\n",
    "    super(DisambiguateClassifier, self).__init__()\n",
    "    self.model = model\n",
    "    self.linear_relu_stack = nn.Sequential(\n",
    "     nn.Linear(self.model.config.hidden_size, 512),\n",
    "     nn.ReLU(),\n",
    "    nn.Linear(512, 348),\n",
    "    )\n",
    "    \n",
    "   # Forward pass through the model\n",
    "    def forward(self, input_ids, token_type_ids, attention_mask ):\n",
    "        output = self.model(\n",
    "        input_ids,\n",
    "       token_type_ids, \n",
    "       attention_mask,)\n",
    "    # Apply the classification head to the last hidden state\n",
    "    out = self.linear_relu_stack (output['last_hidden_state'][:,0,:])\n",
    "    return out\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true,
    "id": "LtjjXn8hlyEz"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DisambiguateClassifier(\n",
       "  (model): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (linear_relu_stack): Sequential(\n",
       "    (0): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=348, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "clinic_model = DisambiguateClassifier(model)\n",
    "clinic_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "Z4rethD4q5YC"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class DisambiguateClassifier(nn.Module):\n",
    "    def __init__(self, model):\n",
    "        super(DisambiguateClassifier, self).__init__()\n",
    "        # Initialize the classifier with the pretrained model and custom classification head\n",
    "        self.model = model\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(768, 512),  # Linear layer with input size 768 and output size 512\n",
    "            nn.Dropout(0.3),  # Dropout layer with dropout probability of 0.3\n",
    "            nn.ReLU(),  # ReLU activation function\n",
    "            nn.Linear(512, 340),  # Linear layer with input size 512 and output size 340\n",
    "            nn.Dropout(0.3),  # Dropout layer with dropout probability of 0.3\n",
    "            nn.ReLU(),  # ReLU activation function\n",
    "            nn.Linear(340, 498),  # Linear layer with input size 340 and output size 498\n",
    "            # nn.Softmax(dim=1)  # Softmax layer (commented out)\n",
    "        )\n",
    "    \n",
    "    def forward(self, input_ids, token_type_ids, attention_mask):\n",
    "        # Forward pass through the model\n",
    "        output = self.model(\n",
    "            input_ids=input_ids,\n",
    "            token_type_ids=token_type_ids, \n",
    "            attention_mask=attention_mask\n",
    "        )\n",
    "        # Apply the classification head to the last hidden state\n",
    "        out = self.linear_relu_stack(output['last_hidden_state'][:, 0, :])\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "from transformers import get_linear_schedule_with_warmup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "99KDT7FBhhmq"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\lib\\site-packages\\transformers\\optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from transformers import AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "# Initialize optimizer\n",
    "optimizer = AdamW(clinic_model.parameters(), lr=1e-5)\n",
    "\n",
    "# Calculate total steps\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "# Initialize scheduler\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Initialize loss function\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "ubM8ehqLqVwP"
   },
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model,\n",
    "    data_loader,\n",
    "    loss_fn,\n",
    "    optimizer,\n",
    "    device,\n",
    "    scheduler,\n",
    "    n_examples\n",
    "):\n",
    "    # Set model to training mode\n",
    "    model = model.train()\n",
    "\n",
    "    # Initialize lists to store losses and correct predictions\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Iterate through data loader\n",
    "    for d in data_loader:\n",
    "        # Move data to device\n",
    "        input_ids = d['input_ids'].to(device)\n",
    "        attention_mask = d['attention_mask'].to(device)\n",
    "        token_type_ids = d['token_type_ids'].to(device)\n",
    "        label = d['label_'].to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(\n",
    "            input_ids,\n",
    "            attention_mask,\n",
    "            token_type_ids,\n",
    "        )\n",
    "\n",
    "        # Calculate loss\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        loss = loss_fn(outputs, label)\n",
    "\n",
    "        # Track correct predictions and losses\n",
    "        correct_predictions += torch.sum(preds == label)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    # Calculate accuracy and average loss\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "KaoodV_Ws4UA"
   },
   "outputs": [],
   "source": [
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    # Set model to evaluation mode\n",
    "    model = model.eval()\n",
    "\n",
    "    # Initialize lists to store losses, correct predictions, and predictions\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "    prediction = []\n",
    "\n",
    "    # Disable gradient calculation\n",
    "    with torch.no_grad():\n",
    "        # Iterate through data loader\n",
    "        for d in data_loader:\n",
    "            # Move data to device\n",
    "            input_ids = d['input_ids'].to(device)\n",
    "            attention_mask = d['attention_mask'].to(device)\n",
    "            token_type_ids = d['token_type_ids'].to(device)\n",
    "            label = d['label_'].to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(\n",
    "                input_ids,\n",
    "                attention_mask,\n",
    "                token_type_ids,\n",
    "            )\n",
    "\n",
    "            # Calculate loss\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            loss = loss_fn(outputs, label)\n",
    "\n",
    "            # Track correct predictions and losses\n",
    "            for p, x, ii in zip(preds, label, input_ids):\n",
    "                if p.item() != x.item():\n",
    "                    print(p.item(), \",\", x.item(), \",\", tokenizer.decode(ii, skip_special_tokens=True))\n",
    "            correct_predictions += torch.sum(preds == label)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "    # Calculate accuracy and average loss\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "9Hh5mCCztUrk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n",
      "Train loss 2.920616456270218 accuracy 0.8241206030150754\n",
      "0 , 3 , type a, type b official reading pending. white blood cell count is elevated at 24. 8 with 96 % neutrophils and hemoglobin of 12. 4. electrocardiogram shows atrial fibrillation with a rapid ventricular response. no sign of ischemia. influenza ab swab is pending at this time. assessment : 1. pneumonia, right lower lobe, possible sepsis. aspiration is possible.\n",
      "Val   loss 1.0326928496360779 accuracy 0.98\n",
      "\n",
      "Epoch 2/2\n",
      "----------\n",
      "Train loss 0.9856191217899323 accuracy 0.9673366834170855\n",
      "0 , 3 , type a, type b official reading pending. white blood cell count is elevated at 24. 8 with 96 % neutrophils and hemoglobin of 12. 4. electrocardiogram shows atrial fibrillation with a rapid ventricular response. no sign of ischemia. influenza ab swab is pending at this time. assessment : 1. pneumonia, right lower lobe, possible sepsis. aspiration is possible.\n",
      "Val   loss 0.5789444616862706 accuracy 0.98\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Initialize defaultdict to store training and validation metrics\n",
    "history = defaultdict(list)\n",
    "\n",
    "# Initialize best accuracy\n",
    "best_accuracy = 0\n",
    "\n",
    "# Loop over each epoch\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f'Epoch {epoch + 1}/{EPOCHS}')\n",
    "    print('-' * 10)\n",
    "\n",
    "    # Train the model for one epoch\n",
    "    train_acc, train_loss = train_epoch(\n",
    "        clinic_model,\n",
    "        train_data_loader,\n",
    "        loss_fn,\n",
    "        optimizer,\n",
    "        device,\n",
    "        scheduler,\n",
    "        len(train_df)\n",
    "    )\n",
    "\n",
    "    # Print training loss and accuracy\n",
    "    print(f'Train loss {train_loss} accuracy {train_acc}')\n",
    "\n",
    "    # Evaluate the model on the validation set\n",
    "    val_acc, val_loss = eval_model(\n",
    "        clinic_model,\n",
    "        val_data_loader,\n",
    "        loss_fn,\n",
    "        device,\n",
    "        len(val_df)\n",
    "    )\n",
    "\n",
    "    # Print validation loss and accuracy\n",
    "    print(f'Val   loss {val_loss} accuracy {val_acc}')\n",
    "    print()\n",
    "\n",
    "    # Update history dictionary with training and validation metrics\n",
    "    history['train_acc'].append(train_acc)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_acc'].append(val_acc)\n",
    "    history['val_loss'].append(val_loss)\n",
    "\n",
    "    # Save the best model if the current validation accuracy is better than the best accuracy\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model.state_dict(), 'best_model_state.bin')\n",
    "        best_accuracy = val_acc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "vSGVikvND7b4"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['train_acc'], label='train accuracy')\n",
    "\n",
    "plt.plot(history['val_acc'], label='validation accuracy')\n",
    "\n",
    "plt.title('Training history')\n",
    "\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "plt.xlabel('Epoch')\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "plt.ylim([0, 1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "nlrBXSmGEGkM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 3 , type a, type b problem # 2 : cough. the patient presented with aggressive cough. she had a chest ct done, which showed minimal central _ _ _ _ _ _ passage to upper lobes bilaterally, a nonspecific finding. the patient had cultures done. at the time of discharge, they were negative for ab by stain. however, cultures will be called several weeks after culture. problem # 3. hypertension. the patient will continue her medications she was on, which includes norvasc and hydrochlorothiazide.\n",
      "0 , 3 , type a, type b a herpes simplex virus swab was sent on his lower lip lesion, although the results were erroneously canceled on the computer. influenza ab was sent and was negative. he had several blood cultures during his hospitalization, as well as a urine culture, which all remained negative, with no growth.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc, _ = eval_model(\n",
    "\n",
    "  clinic_model,\n",
    "\n",
    "  test_data_loader,\n",
    "\n",
    "  loss_fn,\n",
    "\n",
    "  device,\n",
    "\n",
    "  len(test_df)\n",
    "\n",
    ")\n",
    "\n",
    "test_acc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "P_EDrZ4bES9R"
   },
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "\n",
    "  model = model.eval()\n",
    "\n",
    "  text = []\n",
    "\n",
    "  predictions = []\n",
    "\n",
    "  real_values = []\n",
    "  texts = []\n",
    "  \n",
    "\n",
    "  with torch.no_grad():\n",
    "\n",
    "    for d in data_loader:\n",
    "\n",
    "\n",
    "      input_ids = d[\"input_ids\"].to(device)\n",
    "\n",
    "      attention_mask = d[\"attention_mask\"].to(device)\n",
    "      token_type_ids = d[\"token_type_ids\"].to(device)\n",
    "\n",
    "\n",
    "      targets = d[\"label_\"].to(device)\n",
    "\n",
    "      outputs = model(\n",
    "\n",
    "        input_ids=input_ids,\n",
    "\n",
    "        attention_mask=attention_mask,\n",
    "        token_type_ids = token_type_ids,\n",
    "\n",
    "      )\n",
    "\n",
    "      _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "      #for xx in input_ids:\n",
    "        #text.extend(tokenizer.decode(xx,skip_special_tokens=True))\n",
    "\n",
    "      predictions.extend(preds)\n",
    "\n",
    "      real_values.extend(d['label_'])\n",
    "  texts.extend(text)\n",
    "\n",
    "  predictions = torch.stack(predictions).cpu()\n",
    "\n",
    "  #texts = torch.stack(texts).cpu()\n",
    "\n",
    "  real_values = torch.stack(real_values).cpu()\n",
    "\n",
    "  return  predictions, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "Z0EulXWVEcjv"
   },
   "outputs": [],
   "source": [
    "y_pred, y_test = get_predictions(clinic_model,test_data_loader)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "CS2xYcYTmaim"
   },
   "outputs": [],
   "source": [
    "text = []\n",
    "for d in test_data_loader:\n",
    "  for dd in d['input_ids']:\n",
    "    text.append(tokenizer.decode(dd, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PHh__MSs7gkP",
    "outputId": "16930db9-1862-415b-d013-2180f4d60d9a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction = []\n",
    "for i in y_pred:\n",
    "  prediction.append(i.item())\n",
    "len(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "slf3vZWn758X",
    "outputId": "b4318c80-dc5a-457d-b39b-31b4677a8616"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real = []\n",
    "for i in y_test:\n",
    "  real.append(i.item())\n",
    "len(real)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "DbWHI9Yg8E1d"
   },
   "outputs": [],
   "source": [
    "test_result_df = pd.DataFrame()\n",
    "test_result_df['text'] = text\n",
    "test_result_df['prediction'] = prediction\n",
    "test_result_df['real'] = real\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "TCwU7LgO9snW"
   },
   "outputs": [],
   "source": [
    "test_result_df.to_csv('test_result_prediction.tsv', sep = '|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "4yVciTO1EdZC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "#print(classification_report(y_test, y_pred, target_names=class_names))\n",
    "#print(y_pred)\n",
    "for i in y_pred:\n",
    "  print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Qn76A4ho2TvG"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyNR0+AmAA7UB6Ys3t8Cgisz",
   "collapsed_sections": [],
   "name": "PreTrained_ME_BioClinical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
